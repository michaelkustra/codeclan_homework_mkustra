---
title: "R Notebook"
output: html_notebook
---

```{r}
# add relevant packages
library(tidyverse)
library(modelr)
library(GGally)
library(ggfortify)
```

```{r}
# add in housing prices data
kc_housing <- read_csv(here::here("data/kc_house_data.csv"))

dim(kc_housing)
```

# Question 1

## Tidy up the data

```{r}
# remove unnecessary columns
kc_housing_trim <- kc_housing %>% 
  select(-c(date, id, sqft_living15, sqft_lot15, zipcode))
```

## Change waterfront & yr_renovated to logical variables

```{r}
kc_housing_trim <- kc_housing_trim %>% 
  mutate(waterfront = as.logical(waterfront),
         renovated = as.logical(yr_renovated)) %>% 
  select(-yr_renovated)
```

Have a think about how to treat `condition` and `grade`? Are they interval or categorical ordinal data types?

```{r}
# change condition & grade to factor type
kc_housing_trim <- kc_housing_trim %>% 
  mutate(condition = as.factor(condition)) %>% 
  mutate(grade = as.factor(grade))

```

# Question 2

```{r}
# check for aliased variables in trimmed data set
alias(lm(price ~ ., data = kc_housing_trim))
```

__Interpretation__

Using the alias() function we can see that the variable sqft_basement can be 
computed as sqft_living and not sqft_above, thus sqft_basement can be removed
since it is explained by other variables in our data set.

```{r}
# remove sqft_basement due to alias()
kc_housing_trim <- kc_housing_trim %>% 
  select(-sqft_basement)
```

# Question 3

```{r}
kc_housing_numeric <- kc_housing_trim %>%
  select_if(is.numeric)

kc_housing_nonnumeric <- kc_housing_trim %>%
  select_if(function(x) !is.numeric(x))

kc_housing_nonnumeric$price <- kc_housing_trim$price

ggpairs(kc_housing_numeric)
ggpairs(kc_housing_nonnumeric)
```

__Potential Predictors__

* sqft_living
* sqft_above
* bathrooms
* view

# First Predictor

```{r}
# add sqft_living as first predictor for price
mod1a <- lm(price ~ sqft_living, data = kc_housing_trim)

#take log of each variable to scale better
mod1b <- lm(log(price) ~ log(sqft_living), data = kc_housing_trim)
```

## Diagnostic Plots

```{r}
autoplot(mod1a)
autoplot(mod1b)
```

__Interpretation__

In its original format as price ~ sqft_living, my model appears to fail on tests
of all our assumptions. In the normal QQ plot It does not appear to of a normal 
distribution (perhaps right skewed) and it does not hold on constancy of 
variation. The scale-location plot shows evidence of heteroscedasticity.

To remedy this I have taken the log of each variable in order to scale them so
that they may better meet our assumptions. The new plots do appear to show
improvement. The residuals vs fitted shows better variation in our residuals,
it also follows a normal distribution on our normal QQ plot better. The points
no longer show a funnel shape in the scale-location and appear to show
better variation in residuals. 

## Summary of mod1a

```{r}
summary(mod1b)
```

__Summary Interpretation__

Both our intercept and log(sqft_livng) appear statistically significant in our
model with p-values < 0.05. The adjusted R-squared value of 0.4555 indicates
that 45.6% of the response variable is explained by our predictor.

# Second Predictor

```{r}
# calculate residuals and remove current vars in model
housing_numeric_resid <- kc_housing_numeric %>%
  add_residuals(mod1b) %>%
  select(-c(price, sqft_living))

housing_numeric_resid %>%
  ggpairs()

housing_nonnumeric_resid <- kc_housing_nonnumeric %>% 
  add_residuals(mod1b)

housing_nonnumeric_resid %>% 
  ggpairs()
```
__Interpretation__

Based in the pairs plot I would choose `lat` as the next variable for our model,
with a correlation of 0.573 with resid.

```{r}
mod2a <- lm(log(price) ~ log(sqft_living) + lat, data = kc_housing_trim)
```

```{r}
autoplot(mod2a)
```

```{r}
summary(mod2a)
```

__Interpretation__

The model satisfies my assumptions of independence and variation from the 
diagnostic plots.

Each predictor is statistically significant due to their p-values < 0.05 and
the Adjusted R-squared has increased to 0.6343, meaning now 63.4% of our
response is explained by the two predictors, an improvement on mod1b. The 
residual standard error has also stayed low, 0.3185.

# Third Predictor

```{r}
housing_numeric_resid <- kc_housing_numeric %>%
  add_residuals(mod2a) %>%
  select(-c(price, sqft_living, lat))

housing_numeric_resid %>%
  ggpairs()
```

```{r}
# add view to our model
mod3a <- lm(log(price) ~ log(sqft_living) + lat + view, data = kc_housing_trim)
```

```{r}
autoplot(mod3a)
```

```{r}
summary(mod3a)
```

__Interpretation__

All predictors appear statistically significant due to the small p-values
(< 0.05) and our residual standard error has decreased slightly to 0.3028. The
Adjusted R-squared has increased to 0.6694, so now 66.9% of the response is
explained from the predictors.

# Fourth Predictor

```{r}
# check residuals with remaining possible predictors
housing_resid <- kc_housing_trim %>%
  add_residuals(mod3a) %>%
  select(-c(price, sqft_living, lat, view))

housing_resid %>% 
  ggpairs()
```

```{r}
# add sqft_above to the model
mod4a <- lm(log(price) ~ log(sqft_living) + lat + view + grade,
            data = kc_housing_trim)
```

```{r}
autoplot(mod4a)
```

```{r}
summary(mod4a)
```

__Interpretation__

I am satisfied it meets the assumptions after viewing the diagnostic plots
above.

Adjusted R-squared has increased to 0.7261, so 72.6% of the response is now
explained by the predictors. Residual standard error has decreased to 0.2756,
another improvement. Using the ANOVA below I have decided to keep grade in my
model due to its significance, as seen with the p-value < 0.05.


```{r}
# check the grade is stat significant in our model and if it should be kept
anova(mod3a, mod4a)
```

