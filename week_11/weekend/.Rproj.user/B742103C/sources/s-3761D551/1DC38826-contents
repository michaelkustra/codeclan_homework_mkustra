---
title: "Logistic Regression HW"
output: html_notebook
---

```{r}
# load libraries
library(tidyverse)
library(janitor)
library(modelr)
library(GGally)
library(ggfortify)
```


```{r}
# read in orange juice data and clean names
juice_data <- read_csv(here::here("data/orange_juice.csv")) %>% 
  clean_names()
```

```{r}
# change purchase to logic variable
cols <- c("store7", "store_id", "special_ch", "special_mm", "store")

juice_data_clean <- juice_data %>%
  mutate(mm_purchase = case_when(
    purchase == "MM" ~ TRUE,
    purchase == "CH" ~ FALSE
  ), .before = 2) %>% 
  select(-purchase, -weekof_purchase) %>% 
  mutate_at(cols, as.factor)

juice_data_clean %>% 
  distinct(store_id, store)

```

```{r}
# check trends for week of purchase for both oj types
temp_df <- as.data.frame(table(juice_data$purchase, juice_data$weekof_purchase))
colnames(temp_df) <- c("purchase", "week", "frequency")

ggplot(temp_df, aes(x = week, y = frequency, colour = purchase, 
                    group = purchase))+
  geom_point() +
  geom_line() +
  theme_bw() +
  theme(legend.position = "top", axis.text.x = element_text(angle = 90, vjust = 0.5))+
  labs(title = "Number of purchase by week")
```

__Interpretation__
From the above plot I am going to decide to remove `weekof_purchase` from my 
logistic model since there doesn't seem to be a huge difference between the
two types of OJ and week of purchase. 

```{r}
# check for aliased variables
alias(mm_purchase ~ ., data = juice_data_clean)
```

__Interpretation__

Based on the alias output above, I will remove the following variables:

* price_ch
* price_mm
* disc_mm
* disc_ch
* store7
* store

```{r}
# remove aliased variables 
juice_data_clean <- juice_data_clean %>% 
  select(-c(price_ch, price_mm, disc_ch, disc_mm, store7, store))
```

```{r}
# pairs plot for multi-collinearity
ggpairs(juice_data_clean, columns = c(1, 6:11))
```

__Interpretation__

Following predictors stand out to me as promising from the pairs plot:

* loyal_ch (customer brand loyalty score for citrus hill)
* list_price_diff (list price of MM less list price of CH)
* store_id (id of each store in data set)

Also there could be issues with multi-collinearity due to the high positive
correlations between several of the predictors, I will remove the following:

* price_diff
* pct_disc_mm
* pct_disc_ch

```{r}
# remove variables to combat multicollinearity & recheck pairs plot
juice_data_clean <- juice_data_clean %>%
  select(-c(price_diff, pct_disc_mm, pct_disc_ch))

ggpairs(juice_data_clean)
```


```{r}
# split data into test/train sets
n_data <- nrow(juice_data_clean)

test_index <- sample(1:n_data, size = n_data * 0.2)

juice_test <- slice(juice_data_clean, test_index)

juice_train <- slice(juice_data_clean, -test_index)
```

```{r}
# check test/train table ratios
juice_train %>% 
  tabyl(mm_purchase)

juice_test %>% 
  tabyl(mm_purchase)
```

__Interpretation__

Ratios from the test and train data splits appear balanced, no issues here.

```{r}
# first logistic model
juice_log_model_1a <- glm(mm_purchase ~ loyal_ch + list_price_diff + store_id,
                          data = juice_data_clean, 
                          family = binomial(link = 'logit'))

summary(juice_log_model_1a)
```

